{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2 - Mirror symmetry detection\n",
    "*Lorenzo Basile*\n",
    "\n",
    "The aim of this notebook is to build and train a $2$-layer perceptron to detect mirror symmetry in sequences of $6$ bits, as explained in [this](https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf) paper.  \n",
    "The architecture is very easy: $6$ input bits are fed into a first linear layer made of $2$ neurons, then the output of these neurons is processed by a single output neuron. All three neurons in the network have biases and sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_features=6, out_features=2, bias=True)\n",
    "        self.layer2 = nn.Linear(in_features=2, out_features=1, bias=True)\n",
    "    def forward(self, x):\n",
    "        out = torch.sigmoid(self.layer1(x))\n",
    "        out = torch.sigmoid(self.layer2(out))\n",
    "        return out\n",
    "net=NN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be consistent with the original paper, all parameters are initialized uniformly in $[-0.3, 0.3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2928, -0.0865,  0.0185, -0.0434, -0.2614,  0.0473],\n",
      "        [-0.2341, -0.0445, -0.2855, -0.1742, -0.1498, -0.1514]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2702, 0.0345], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1845, -0.0547]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1955], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    torch.nn.init.uniform_(p, a=-0.3, b=0.3)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is useful to define mirror symmetry: a sequence (`torch.tensor`) is mirrored if it is equal to itself flipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirrored(seq):\n",
    "    if torch.equal(seq, torch.flip(seq, [0])):\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data and labels are generated here: each data point is assigned label `1` if it has mirror symmetry, `0` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in product(range(2), repeat=6)]\n",
    "x=torch.tensor(x, dtype=torch.float32)\n",
    "y=torch.zeros((len(x),1))\n",
    "for i in range(len(x)):\n",
    "    y[i]=mirrored(x[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make training easier, a `DataLoader` object is created. `batch_size` is set to $64$ (one mini-batch contains the whole dataset) to take away the stochasticity in the SGD algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_utils.TensorDataset(x, y)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is here performed in the same way presented in the paper, using `lr=0.1`, `momentum=0.9`and `MSELoss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
    "loss = torch.nn.MSELoss()\n",
    "for epoch in range(10000):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        seq=data[0]\n",
    "        label=data[1]\n",
    "        out=net(seq)\n",
    "        l=loss(out, label)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This training loop, despite being relatively long, is not sufficient to reach high accuracy: all mirror samples are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples:  8.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Misclassified samples: \", torch.sum(torch.abs((net(x)>0.5).float()-y)).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, parameters do not show the symmetry properties advertised in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1932, -0.1070,  0.0657, -0.0578, -0.1712,  0.0142],\n",
      "        [ 0.0114, -0.0198, -0.1391, -0.0313,  0.0106, -0.1275]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2684, 0.1342], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3596, -0.4916]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.5183], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters():\n",
    "    print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
