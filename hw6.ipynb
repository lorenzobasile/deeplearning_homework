{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 6 - U-Net\n",
    "*Lorenzo Basile*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the implementation of a U-Net style CNN, with the following specifications:\n",
    "- All convolutions use a 3 x 3 kernel and leave the spatial dimensions of the input untouched (this is obtained by using padding);\n",
    "- Downsampling in the contracting part is performed via maxpooling with a 2 x 2 kernel and stride of 2;\n",
    "- Upsampling is operated by a deconvolution with a 2 x 2 kernel and stride of 2.\n",
    "- The final layer of the expanding part has only 1 channel\n",
    "\n",
    "The final point means that this network could be used to perform binary segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is made of two kinds of submodules: contracting and expanding.  \n",
    "A contracting module is the series of a max pooling layer (excluded the input layer) and two convolutional layers with ReLU activations.  \n",
    "The expanding part is slightly more complex: the input is passed through an upsampling layer which doubles its dimensions and then concatenated with a cropped copy of the output of the corresponding contracting module. Then, the result of this concatenation is fed into the series of two convolutional layers with ReLU activations.\n",
    "\n",
    "If pooling is never applied to an odd sized image (in this specific case this condition translates to having input images with dimensions which are multiples of 16), this network leaves the dimensions of the input untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class contracting_module(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self, index):\n",
    "        super().__init__()\n",
    "        self.output_channels=2**(6+index)\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2) if index!=0 else nn.Identity(),\n",
    "            nn.Conv2d(in_channels=self.output_channels//2 if index!=0 else 1, out_channels=self.output_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=self.output_channels, out_channels=self.output_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class expanding_module(torch.nn.Module):\n",
    "        \n",
    "    def __init__(self, index):\n",
    "        super().__init__()\n",
    "        self.output_channels=2**(6+index)\n",
    "        self.upsampling=nn.ConvTranspose2d(in_channels=self.output_channels*2, out_channels=self.output_channels, kernel_size=2, stride=2)\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=self.output_channels*2, out_channels=self.output_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=self.output_channels, out_channels=self.output_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, copy):\n",
    "        x=self.upsampling(x)\n",
    "        cropped_copy=transforms.CenterCrop(size=x.shape[-1])(copy)\n",
    "        x=torch.cat([cropped_copy, x], dim=1)\n",
    "        return self.layers(x)\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.contracting_modules=[contracting_module(i) for i in range(5)]\n",
    "        self.expanding_modules=[expanding_module(i) for i in range(4)]\n",
    "        self.final_layer=nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        x=copy_0=self.contracting_modules[0](x)\n",
    "        x=copy_1=self.contracting_modules[1](x)\n",
    "        x=copy_2=self.contracting_modules[2](x)\n",
    "        x=copy_3=self.contracting_modules[3](x)\n",
    "        x=self.contracting_modules[4](x)\n",
    "        x=self.expanding_modules[3](x, copy_3)\n",
    "        x=self.expanding_modules[2](x, copy_2)\n",
    "        x=self.expanding_modules[1](x, copy_1)\n",
    "        x=self.expanding_modules[0](x, copy_0)\n",
    "        x=self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 512])\n",
      "torch.Size([1, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "net=UNet()\n",
    "input=torch.rand((1,1,512,512))\n",
    "print(input.shape)\n",
    "print(net(input).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
